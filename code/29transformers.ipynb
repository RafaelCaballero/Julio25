{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelCaballero/Julio25/blob/main/code/29transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z08HYDKZWZ0q"
      },
      "source": [
        "# Introducción a la ciencia de datos con Python\n",
        "Rafael Caballero\n",
        "\n",
        "## Transformers\n",
        "\n",
        "Los transformers son un tipo de red neuronal:\n",
        "\n",
        "- Procesa secuencias enteras a la vez mediante un mecanismo llamado \"self-attention\", identificando qué partes del texto (o de la señal) se influyen mutuamente\n",
        "\n",
        "- Es paralelizable y escala de forma casi lineal con el tamaño del modelo y los datos, convirtiéndolo en la base de los grandes modelos de lenguaje actuales.\n",
        "\n",
        "\n",
        "Vamos a ver ejemplos tomados y adaptados de\n",
        "\n",
        "[https://www.kaggle.com/code/assiri/huggingface-simple-examples](https://www.kaggle.com/code/assiri/huggingface-simple-examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UR6vG2ZxlOWC"
      },
      "outputs": [],
      "source": [
        "#!pip install transformers\n",
        "#!pip uinstall pgrade torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-H1vQ4YkWY1Y"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bnm0zsqCZVuy"
      },
      "outputs": [],
      "source": [
        "nlp = pipeline('sentiment-analysis')\n",
        "nlp('We are very happy to include pipeline into the transformers repository.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgMPGWQ9cLWv"
      },
      "source": [
        "Probar con la frase que se desee"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rySjjOXPcKcg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCrTo_wVahU5"
      },
      "source": [
        "Pero ¿y en español?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yMZ-4E7Zewh"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "MODEL = \"UMUTeam/roberta-spanish-sentiment-analysis\"  # RoBERTa en español\n",
        "\n",
        "sentiment = pipeline(\n",
        "    task=\"sentiment-analysis\",\n",
        "    model=MODEL,\n",
        "    tokenizer=MODEL,     # usa el mismo tokenizer\n",
        "    return_all_scores=False,  # True → devuelve las 3 probabilidades\n",
        ")\n",
        "\n",
        "texto = \"¡Esta película es fantástica: me ha encantado!\"\n",
        "print(sentiment(texto))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nBlRCVWcAjY"
      },
      "outputs": [],
      "source": [
        "texto = \"Por una parte está bien, por otra parte deja bastante que desear\"\n",
        "print(sentiment(texto))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDMvLcZajXME"
      },
      "source": [
        "Máscaras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgQeMeaTjYYd"
      },
      "outputs": [],
      "source": [
        "nlp = pipeline('fill-mask')\n",
        "nlp('I miss you. The last time I <mask> you was the best moment of my life')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7N-N5U0kik0"
      },
      "source": [
        "NER\n",
        "\n",
        "La idea es detectar nombres propios y decidir de qué son"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSgc3CxngzXe"
      },
      "outputs": [],
      "source": [
        "mi_empresa = \"\"\"\n",
        "Mr. Sánchez anchors the Human Resources training unit.\n",
        "He designs in-house courses on leadership, compliance, and emerging tech.\n",
        "His workshops earn ISO accreditation and keep skills razor-sharp.\n",
        "Mrs. Carrington, also HR, wields the hiring-and-firing sword.\n",
        "She scouts talent, negotiates contracts, and delivers tough exit interviews.\n",
        "Together they cover growth and pruning—the full HR lifecycle.\n",
        "Mr. Lux commands the Accounting desk with forensic precision.\n",
        "He audits ledgers daily, closes the books monthly, and protects cash flow.\n",
        "Riggeti leads IT cybersecurity, guarding servers against zero-day threats.\n",
        "He runs penetration tests at dawn and patches firewalls before lunch.\n",
        "Gertrudis heads the Marketing think-tank.\n",
        "She crafts viral campaigns, tracks KPIs, and talks ROI like a stockbroker.\n",
        "Her data-driven slogans boosted brand reach 37 % last quarter.\n",
        "Mrs. Miller drives Research & Development.\n",
        "She prototypes sustainable materials and files patents at breakneck speed.\n",
        "Her latest bio-polymer cut production costs by 12 %.\n",
        "Johnson orchestrates the Logistics nerve center.\n",
        "He reroutes shipments in real time and slashes delivery delays.\n",
        "His AI-powered routing saved 50 tons of CO₂ this year.\n",
        "\"\"\"\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
        "\n",
        "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "res = nlp(mi_empresa)\n",
        "res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8ezDMNAirbu"
      },
      "source": [
        "Resumen de textos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "text = 'Shakespeare occupies a position unique in world literature. Other poets, such as Homer and Dante, and novelists, such as Leo Tolstoy and Charles Dickens, have transcended national barriers, but no writer’s living reputation can compare to that of Shakespeare, whose plays, written in the late 16th and early 17th centuries for a small repertory theatre, are now performed and read more often and in more countries than ever before. The prophecy of his great contemporary, the poet and dramatist Ben Jonson, that Shakespeare “was not of an age, but for all time,” has been fulfilled. It may be audacious even to attempt a definition of his greatness, but it is not so difficult to describe the gifts that enabled him to create imaginative visions of pathos and mirth that, whether read or witnessed in the theatre, fill the mind and linger there. He is a writer of great intellectual rapidity, perceptiveness, and poetic power. Other writers have had these qualities, but with Shakespeare the keenness of mind was applied not to abstruse or remote subjects but to human beings and their complete range of emotions and conflicts. Other writers have applied their keenness of mind in this way, but Shakespeare is astonishingly clever with words and images, so that his mental energy, when applied to intelligible human situations, finds full and memorable expression, convincing and imaginatively stimulating. As if this were not enough, the art form into which his creative energies went was not remote and bookish but involved the vivid stage impersonation of human beings, commanding sympathy and inviting vicarious participation. Thus, Shakespeare’s merits can survive translation into other languages and into cultures remote from that of Elizabethan England.'\n",
        "\n"
      ],
      "metadata": {
        "id": "RUU3a-O7ntyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVgT0uV6iwx0"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
        "\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "inputs = tokenizer.batch_encode_plus([text], max_length=1024, return_tensors='pt',truncation=True)\n",
        "\n",
        "summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=100, early_stopping=False)\n",
        "\n",
        "for ids in summary_ids:\n",
        "    short = tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
        "    print(len(text), len(short))\n",
        "    print(short)\n",
        "\n"
      ],
      "metadata": {
        "id": "6i0BD6aboL5X"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}