{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelCaballero/Julio25/blob/main/code/17otras_regresiones.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59cy_yTIHUG2"
      },
      "source": [
        "# Introducción a la ciencia de datos con Python\n",
        "### Rafa Caballero\n",
        "\n",
        "\n",
        "## Otros métodos de regresión\n",
        "\n",
        "Listamos todos los regresores disponibles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yAlWp1rHUG4"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils  import all_estimators\n",
        "from sklearn import base\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "estimators = all_estimators()\n",
        "\n",
        "for name, class_ in estimators:\n",
        "    if issubclass(class_, base.RegressorMixin):\n",
        "        print(name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emcsH_KsHUG5"
      },
      "source": [
        "Lista de todas las métricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2gBWC6THUG5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import get_scorer_names\n",
        "get_scorer_names()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv8FySJVHUG5"
      },
      "source": [
        "Vamos a probar algunos de estos regresores, sin ajustar hiperparámetros\n",
        "\n",
        "- [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html): la regresión lineal pura, ya vista<br>\n",
        "\n",
        "- [GradientBoostingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html): método iterativo muy configurable, que va mirando hacía donde desciende una función de loss.\n",
        "\n",
        "- [AdaBoostRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html): utiliza un regresor, mide el error cometido y lo va adaptando para mejorar\n",
        "\n",
        "- [DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html): Método basado en los árboles de decisión\n",
        "\n",
        "- [RadomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html): Utiliza múltiples árboles de decisión para decidir qué punto ajusta mejor. Muy potente pero bastante lento.\n",
        "\n",
        "- [SVR](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html) : Epsilon-Support Vector Regression. Basado en support Vector Machines. Un método que no debe usarse para demasiados datos (>10000) puede ser muy lento<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Divd2dVHUG5"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import  RandomForestRegressor\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import explained_variance_score, r2_score,mean_squared_error,mean_absolute_error\n",
        "import math\n",
        "\n",
        "def evalua(regresor,X,y,x_train, y_train,x_test,y_test,label=\"grafico\"):\n",
        "        mod = regresor.fit(x_train,y_train)\n",
        "        y_pred = mod.predict(x_test) # predicciones test\n",
        "\n",
        "        test = x_test.copy()\n",
        "        test['y'] = np.array(y_pred)\n",
        "        test= pd.DataFrame.sort_index(test)\n",
        "\n",
        "\n",
        "        ##############################\n",
        "        # errores\n",
        "        y_true = y_test\n",
        "        rmse =  mean_squared_error(y_true,y_pred,squared=True)\n",
        "        mae = mean_absolute_error(y_true,y_pred)\n",
        "        fig, ax = plt.subplots(figsize=(10, 4),dpi=100)\n",
        "\n",
        "        ax.scatter(x=X,y=y,color=\"green\",s=5)\n",
        "        titulo = label+\". MAE: %0.2f \"%mae+\" RMSE %0.2f\"%rmse\n",
        "        ax.scatter(x=test['x'],y=test['y'], color='red',s=4,label=label)\n",
        "        plt.title(titulo)\n",
        "        plt.show()\n",
        "        return titulo\n",
        "def muestra(X,y):\n",
        "    metodos = [(\"LinearRegression\",LinearRegression()),\n",
        "               (\"GradientBoostingRegressor\",GradientBoostingRegressor()),\n",
        "               (\"AdaBoostRegressor\",AdaBoostRegressor()),\n",
        "               (\"RandomForestRegressor\",RandomForestRegressor()),\n",
        "               (\"DecisionTreeRegressor\",DecisionTreeRegressor()),\n",
        "               (\"SVR\",SVR())\n",
        "\n",
        "              ]\n",
        "\n",
        "    test = 0.4\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= test)\n",
        "    report = \"\"\n",
        "    for i,(nombre,metodo) in enumerate(metodos):\n",
        "        t = evalua(metodo,X,y,X_train, y_train,X_test,y_test,nombre)\n",
        "        report += \"\\n\"+t\n",
        "\n",
        "    print(report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I11xMJqoHUG6"
      },
      "source": [
        "1.- Regresión lineal \"perturbada\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iPGwdD7HUG6"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# genera datos aleatorios alrededor del eje x=y\n",
        "# perturbacion: numero de cambios (sobre 100)\n",
        "# grado: incremento de la perturbacion,\n",
        "# locos: % de valores sin relación con los datos originales\n",
        "def genera_datos(perturbacion=0,rango=0,n=1000,loco=4):\n",
        "    data =  np.array([ [i,2*i+1,0] for i in range(n)])\n",
        "\n",
        "    dataset = pd.DataFrame(data=data[1:,:],    # values\n",
        "                  # 1st column as index\n",
        "                  columns=data[0,:])\n",
        "    df=dataset.astype(float)\n",
        "    df.columns = ['x','y','perturbada']\n",
        "    df['perturbada'] = df['y']\n",
        "    max = np.max(df['y'])\n",
        "    min = np.min(df['y'])\n",
        "    # ahora perturbamos a la perturbada\n",
        "    for i in range(len(df.index)):\n",
        "        valorloco = random.randrange(100)<=loco\n",
        "        if valorloco:\n",
        "            df.iloc[i,2] = random.randrange(min,max)\n",
        "        else:\n",
        "            valor = random.randrange(100)\n",
        "\n",
        "            hayquepertubar =  valor<=perturbacion\n",
        "            #print(valor,perturbacion,hayquepertubar)\n",
        "            if hayquepertubar:\n",
        "                cuanto = random.randrange(rango)\n",
        "                if random.randrange(2)==0:\n",
        "                     cuanto *= -1\n",
        "                df.iloc[i,2] =  df.iloc[i,1]+cuanto\n",
        "\n",
        "    return df\n",
        "\n",
        "df = genera_datos(perturbacion=85,rango=50,n=100, loco=15)\n",
        "\n",
        "\n",
        "# tamaño del testo: 0.2\n",
        "X = df['x'].to_frame()\n",
        "y = df['perturbada'].to_frame()\n",
        "\n",
        "muestra(X,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvbOaB2NHUG6"
      },
      "source": [
        "2.- \"Látigo\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzAA7zeZHUG6"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "n = 20\n",
        "data =  np.array([ [i,math.sin(i)*i] for i in np.arange(0,n,0.1)])\n",
        "\n",
        "dataset = pd.DataFrame(data=data,    # values\n",
        "                  # 1st column as index\n",
        "                  columns=['x','y'])\n",
        "df=dataset.astype(float)\n",
        "X = df['x'].to_frame()\n",
        "y = df['y'].to_frame()\n",
        "\n",
        "\n",
        "muestra(X,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU_I7TaPHUG6"
      },
      "source": [
        "3.- Función salto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ER7XC7keHUG6"
      },
      "outputs": [],
      "source": [
        "n = 200\n",
        "data1 =  [ [i,10] for i in range(n)]\n",
        "data2 =  [ [i,100] for i in range(n,n*2)]\n",
        "\n",
        "\n",
        "dataset = pd.DataFrame(data=data1+data2,    # values\n",
        "                  # 1st column as index\n",
        "                  columns=data[0,:])\n",
        "df=dataset.astype(float)\n",
        "df.columns = ['x','y']\n",
        "X = df['x'].to_frame()\n",
        "y = df['y'].to_frame()\n",
        "\n",
        "\n",
        "muestra(X,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RE5VqvtHUG7"
      },
      "source": [
        "4.- Semicírculo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnbIGrBuHUG7"
      },
      "outputs": [],
      "source": [
        "n = 20\n",
        "data1 =  [ [x,y] for x in np.arange(10,n,0.1) for y in np.arange(10,n,0.1) if (x*x+y*y)<n*n and (x*x+y*y)>n*(n-1)]\n",
        "\n",
        "\n",
        "\n",
        "dataset = pd.DataFrame(data=data1,    # values\n",
        "                  # 1st column as index\n",
        "                  columns=data[0,:])\n",
        "df=dataset.astype(float)\n",
        "df.columns = ['x','y']\n",
        "X = df['x'].to_frame()\n",
        "y = df['y'].to_frame()\n",
        "\n",
        "\n",
        "muestra(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8LQATtkHUG7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRNyXfCHHUG7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}