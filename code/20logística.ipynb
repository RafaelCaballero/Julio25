{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelCaballero/Julio25/blob/main/code/20log%C3%ADstica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4465cf14",
      "metadata": {
        "id": "4465cf14"
      },
      "source": [
        "# Introducción a la ciencia de datos con Python\n",
        "### Rafa Caballero\n",
        "\n",
        "## Regresión logística\n",
        "\n",
        "\n",
        "### Índice\n",
        "[Ejemplo](#ejemplo)<br>\n",
        "[Clases desequilibradas](#desequilibrio)<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;[Undersampling](#undersampling)<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;[Oversampling](#oversampling)<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;[Smote](#smote)<br>\n",
        "[Aplicación a validación cruzada](#cruzada)<br>\n",
        "[Interpretación de los coeficientes](#coeficientes)<br>\n",
        "[Curva ROC](#roc)<br>\n",
        "\n",
        "<a name=\"ejemplo\"></a>\n",
        "### Ejemplo\n",
        "Partimos del ejemplo de los autobuses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05f25c09",
      "metadata": {
        "id": "05f25c09"
      },
      "outputs": [],
      "source": [
        "file = \"https://raw.githubusercontent.com/RafaelCaballero/tdm/master/datos/bus.csv\"\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(file)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41b8d059",
      "metadata": {
        "id": "41b8d059"
      },
      "outputs": [],
      "source": [
        "df.I8.hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbe42b64",
      "metadata": {
        "id": "fbe42b64"
      },
      "source": [
        "Consideramos que un autobús llega tarde cuando tarda más de 580 segundos en este último trayecto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fa0a05a",
      "metadata": {
        "id": "1fa0a05a"
      },
      "outputs": [],
      "source": [
        "df[\"label\"] = 1\n",
        "df.loc[df.I8<580, \"label\"] = 0\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "648685a0",
      "metadata": {
        "id": "648685a0"
      },
      "source": [
        "Ojo porque al hacer esto tenemos que eliminar el dato I8 (¿por qué?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eefd43ce",
      "metadata": {
        "id": "eefd43ce"
      },
      "outputs": [],
      "source": [
        "df2 = df.drop(columns=[\"I8\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2[\"label\"].value_counts()"
      ],
      "metadata": {
        "id": "iwMV4_0mfkoY"
      },
      "id": "iwMV4_0mfkoY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf058818",
      "metadata": {
        "id": "bf058818"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "df3 = df2.sort_values(by=\"label\")\n",
        "x=range(len(df3))\n",
        "plt.scatter(x,df3.label,s=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejemplo de función para evaluar la clasificación"
      ],
      "metadata": {
        "id": "9pHFlh9DvhpR"
      },
      "id": "9pHFlh9DvhpR"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "def evaluar(y_test,y_pred):\n",
        "  k =  cohen_kappa_score(y_test,y_pred)\n",
        "  print(\"kappa \",k)\n",
        "  cm = confusion_matrix(y_test, y_pred, labels=modelo.classes_)\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                                display_labels=modelo.classes_)\n",
        "  disp.plot()\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  return k,cm\n"
      ],
      "metadata": {
        "id": "D9BzGY3_vgRa"
      },
      "id": "D9BzGY3_vgRa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2"
      ],
      "metadata": {
        "id": "IvefwasQggZA"
      },
      "id": "IvefwasQggZA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf192c72",
      "metadata": {
        "id": "bf192c72"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# 1 dividir columnas\n",
        "yColumn = \"label\"\n",
        "XColumns = [c for c in df2.columns if c!=yColumn] # [\"hora,\"I0\",....]\n",
        "X = df[XColumns]\n",
        "y = df[yColumn]\n",
        "\n",
        "# 2 preparar train y test\n",
        "test = 0.4\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= test)\n",
        "\n",
        "# 3 método y entrenamiento\n",
        "metodo = LogisticRegression(max_iter=1000)\n",
        "modelo = metodo.fit(X_train,y_train)\n",
        "\n",
        "# 4 evaluar\n",
        "y_pred = modelo.predict(X_test)\n",
        "evaluar(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe01461a",
      "metadata": {
        "id": "fe01461a"
      },
      "source": [
        "<a name=\"desequilibrio\"></a>\n",
        "### Clases desequilibradas\n",
        "Lo que está ocurriendo es que al haber pocos 1's, el sistema no \"aprende\" a reconocerlos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99272109",
      "metadata": {
        "id": "99272109"
      },
      "outputs": [],
      "source": [
        "y.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "988b2a66",
      "metadata": {
        "id": "988b2a66"
      },
      "source": [
        "Posibilidades:\n",
        "\n",
        "\n",
        "<a name=\"undersampling\"></a>\n",
        "#### Undersampling\n",
        "\n",
        "El undersampling o *submuestreo*  limita la cantidad del valor que más se repite, en este caso el 0. Vamos a hacerlo primero a mano para entenderlo, y luego usaremos una librería. Los dos primeros pasos son igual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f709b4bb",
      "metadata": {
        "id": "f709b4bb"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "# 1 dividir columnas\n",
        "yColumn = \"label\"\n",
        "XColumns = [c for c in df2.columns if c!=yColumn]\n",
        "X = df[XColumns]\n",
        "y = df[yColumn]\n",
        "\n",
        "# 2 preparar train y test\n",
        "test = 0.4\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= test)\n",
        "\n",
        "X_train, y_train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da339e56",
      "metadata": {
        "id": "da339e56"
      },
      "outputs": [],
      "source": [
        "train_unos = y_train[y_train==1]\n",
        "train_ceros = y_train[y_train==0].sample(len(train_unos))\n",
        "\n",
        "y_train_equilibrado = pd.concat([train_unos,train_ceros])\n",
        "\n",
        "y_train_equilibrado = y_train_equilibrado.sample(len(y_train_equilibrado)) # para barajarlos\n",
        "\n",
        "X_train_equilibrado = X_train.loc[y_train_equilibrado.index]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adaebc66",
      "metadata": {
        "id": "adaebc66"
      },
      "outputs": [],
      "source": [
        "y_train_equilibrado, X_train_equilibrado"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58d6f567",
      "metadata": {
        "id": "58d6f567"
      },
      "source": [
        "Ahora tenemos las 2 clases equilibradas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d86ec139",
      "metadata": {
        "id": "d86ec139"
      },
      "outputs": [],
      "source": [
        "(y_train_equilibrado==0).sum(),(y_train_equilibrado==1).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10a6da90",
      "metadata": {
        "id": "10a6da90"
      },
      "outputs": [],
      "source": [
        "# 3 método y entrenamiento\n",
        "metodo = LogisticRegression(max_iter=100000)\n",
        "modelo = metodo.fit(X_train_equilibrado,y_train_equilibrado)\n",
        "\n",
        "# 4 evaluar\n",
        "y_pred = modelo.predict(X_test)\n",
        "evaluar(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee38d21d",
      "metadata": {
        "id": "ee38d21d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "8d844952",
      "metadata": {
        "id": "8d844952"
      },
      "source": [
        "<a name=\"oversampling\"></a>\n",
        "#### Oversampling\n",
        "\n",
        "El oversampling o *sobremuestreo*  añade repeticiones del valor más escaso, en este caso el 1. La idea es la misma, solo que usamos muestreo con repetición en la clase de menos elementos. Suele dar mejor resultado si hay pocos valores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acc27582",
      "metadata": {
        "id": "acc27582"
      },
      "outputs": [],
      "source": [
        "# 2 continuación\n",
        "train_ceros = y_train[y_train==0]\n",
        "train_unos = y_train[y_train==1].sample(len(train_ceros),replace=True) # con reemplazamiento\n",
        "\n",
        "y_train_equilibrado = pd.concat([train_unos,train_ceros])\n",
        "y_train_equilibrado = y_train_equilibrado.sample(len(y_train_equilibrado)) # para barajarlos\n",
        "X_train_equilibrado = X_train.loc[y_train_equilibrado.index]\n",
        "\n",
        "# 3 método y entrenamiento\n",
        "metodo = LogisticRegression(max_iter=100000)\n",
        "modelo = metodo.fit(X_train_equilibrado,y_train_equilibrado)\n",
        "\n",
        "# 4 evaluar\n",
        "y_pred = modelo.predict(X_test)\n",
        "evaluar(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca6873a2",
      "metadata": {
        "id": "ca6873a2"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_pred, labels=modelo.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=modelo.classes_)\n",
        "disp.plot()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3300d76",
      "metadata": {
        "id": "e3300d76"
      },
      "outputs": [],
      "source": [
        "# 3 método y entrenamiento\n",
        "metodo = LogisticRegression(max_iter=100000)\n",
        "modelo = metodo.fit(X_train_equilibrado,y_train_equilibrado)\n",
        "\n",
        "# 4 evaluar\n",
        "y_pred = modelo.predict(X_test)\n",
        "evaluar(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7e0e163",
      "metadata": {
        "id": "b7e0e163"
      },
      "source": [
        "<a name=\"smote\"></a>\n",
        "#### SMOTE\n",
        "\n",
        "Este método genera nuevos valores interpolando otros existentes para la nueva etiqueta, no duplica sin más"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3dd7f1d",
      "metadata": {
        "id": "b3dd7f1d"
      },
      "outputs": [],
      "source": [
        "!pip install imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6295cdb",
      "metadata": {
        "id": "e6295cdb"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# 2 continuación\n",
        "\n",
        "sm = SMOTE()\n",
        "X_train_equilibrado, y_train_equilibrado = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "# 3 método y entrenamiento\n",
        "metodo = LogisticRegression(max_iter=100000)\n",
        "modelo = metodo.fit(X_train_equilibrado,y_train_equilibrado)\n",
        "\n",
        "# 4 evaluar\n",
        "y_pred = modelo.predict(X_test)\n",
        "evalua()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a48a9a7f",
      "metadata": {
        "id": "a48a9a7f"
      },
      "outputs": [],
      "source": [
        "# 3 método y entrenamiento\n",
        "metodo = LogisticRegression(max_iter=100000)\n",
        "modelo = metodo.fit(X_train_equilibrado,y_train_equilibrado)\n",
        "\n",
        "# 4 evaluar\n",
        "y_pred = modelo.predict(X_test)\n",
        "evaluar(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0e3ef7d",
      "metadata": {
        "id": "f0e3ef7d"
      },
      "source": [
        "**Importante**: aplicar estas transformaciónes solo al train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c8c9cbd",
      "metadata": {
        "id": "7c8c9cbd"
      },
      "source": [
        "Además, la biblioteca *imbalanced learn* incorpora también los métodos de undersamping y oversampling haciendo más sencilla la tarea:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf46f1b4",
      "metadata": {
        "id": "bf46f1b4"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# 2 continuación\n",
        "\n",
        "sm = RandomOverSampler()\n",
        "X_train_equilibrado, y_train_equilibrado = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "# 3 método y entrenamiento\n",
        "metodo = LogisticRegression(max_iter=100000)\n",
        "modelo = metodo.fit(X_train_equilibrado,y_train_equilibrado)\n",
        "\n",
        "# 4 evaluar\n",
        "y_pred = modelo.predict(X_test)\n",
        "evaluar(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a606572",
      "metadata": {
        "id": "9a606572"
      },
      "source": [
        "<a name=\"cruzada\"></a>\n",
        "### Aplicación a validación cruzada\n",
        "\n",
        "Como se ve la biblioteca nos permite escribir código más simple (reduciendo la posibilidad de error), pero es que además nos permite utilizarlo con validación cruzada para obtener resultados más sencillos.\n",
        "\n",
        "Hay que notar que la validación cruzada se complica en el caso del equilibrado porque en cada caso tenemos un test distinto y todo se hace internamente. Tenemos que pasarle a la funcion de validación un método de ML que equilibre antes de aplicar la técnica correspondiente. Esto se logra gracias a los pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04e4afc6",
      "metadata": {
        "id": "04e4afc6"
      },
      "outputs": [],
      "source": [
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "steps = [('over', RandomOverSampler()), ('logistic', LogisticRegression(max_iter=10000))]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "repartidor = RepeatedStratifiedKFold(n_splits=10, n_repeats=3)\n",
        "scores = cross_val_score(pipeline, X, y, scoring='balanced_accuracy', cv=repartidor)\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f752ece4",
      "metadata": {
        "id": "f752ece4"
      },
      "outputs": [],
      "source": [
        "scores.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b11928e6",
      "metadata": {
        "id": "b11928e6"
      },
      "outputs": [],
      "source": [
        "steps = [('over', RandomUnderSampler()), ('logistic', LogisticRegression())]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3)\n",
        "scores = cross_val_score(pipeline, X, y, scoring='balanced_accuracy', cv=cv)\n",
        "scores.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24a31ca3",
      "metadata": {
        "id": "24a31ca3"
      },
      "source": [
        "Sin oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dab8d37",
      "metadata": {
        "id": "0dab8d37"
      },
      "outputs": [],
      "source": [
        "steps = [ ('logistic', LogisticRegression())]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3)\n",
        "scores = cross_val_score(pipeline, X, y, scoring='balanced_accuracy', cv=cv)\n",
        "scores.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92e03aea",
      "metadata": {
        "id": "92e03aea"
      },
      "source": [
        "Ojo con usar solo accuracy sin oversampling, nos puede decir que está muy bien porque ignora la clase que se repite menos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "327eef34",
      "metadata": {
        "id": "327eef34"
      },
      "outputs": [],
      "source": [
        "steps = [ ('logistic', LogisticRegression())]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3)\n",
        "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv)\n",
        "scores.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54b3d187",
      "metadata": {
        "id": "54b3d187"
      },
      "source": [
        "En caso de duda lo mejor es obtener la matriz de confusión por validación cruzada, que se puede obtener a partir de\n",
        "[cross_val_predict](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3cb0fcc",
      "metadata": {
        "id": "b3cb0fcc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "steps = [ ('logistic', LogisticRegression())]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "\n",
        "y_pred = cross_val_predict(pipeline, X, y, cv=10)\n",
        "cm = confusion_matrix(y, y_pred, labels=modelo.classes_,normalize=\"true\")\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=modelo.classes_)\n",
        "disp.plot()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bdfc29b",
      "metadata": {
        "id": "5bdfc29b"
      },
      "outputs": [],
      "source": [
        "steps = [('over', RandomOverSampler()), ('logistic', LogisticRegression())]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "y_pred = cross_val_predict(pipeline, X, y, cv=10)\n",
        "cm = confusion_matrix(y, y_pred, labels=modelo.classes_,normalize=\"true\")\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=modelo.classes_)\n",
        "disp.plot()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d6ceee3",
      "metadata": {
        "id": "2d6ceee3"
      },
      "source": [
        "<a name=\"coeficientes\"></a>\n",
        "### Interpretación de los coeficientes"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0mkfQvMYr4RM"
      },
      "id": "0mkfQvMYr4RM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0084a4fd",
      "metadata": {
        "id": "0084a4fd"
      },
      "outputs": [],
      "source": [
        "modelo = LogisticRegression().fit(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b159c7b",
      "metadata": {
        "id": "1b159c7b"
      },
      "outputs": [],
      "source": [
        "v1 = [8,471.0, 650, 370, 280,  1020.6,  665, 420]\n",
        "v2 = [8,471.0, 650, 370, 280,  980,  640, 390]\n",
        "\n",
        "modelo.predict_proba([v1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c8122ad",
      "metadata": {
        "id": "3c8122ad"
      },
      "outputs": [],
      "source": [
        "modelo.predict_proba([v2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "109d721c",
      "metadata": {
        "id": "109d721c"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(modelo.coef_,columns=X.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44f0cc5b",
      "metadata": {
        "id": "44f0cc5b"
      },
      "source": [
        "Vemos que el que más influye es la hora, y después el I7. Es difícil interpretar el signo negativo de la hora, quizás sea mejor convertirla a one-hot encoding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6e4455d",
      "metadata": {
        "id": "c6e4455d"
      },
      "outputs": [],
      "source": [
        "X2 = X.copy()\n",
        "X2[\"Hora\"] = X.Hora.astype(str)\n",
        "X2 = pd.get_dummies(X2)\n",
        "X2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1593e75d",
      "metadata": {
        "id": "1593e75d"
      },
      "outputs": [],
      "source": [
        "steps = [('over', RandomUnderSampler()), ('logistic', LogisticRegression())]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3)\n",
        "scores = cross_val_score(pipeline, X2, y, scoring='balanced_accuracy', cv=cv)\n",
        "scores.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b97399ff",
      "metadata": {
        "id": "b97399ff"
      },
      "outputs": [],
      "source": [
        "steps = [('over', RandomUnderSampler()), ('logistic', LogisticRegression())]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3)\n",
        "scores = cross_val_score(pipeline, X, y, scoring='balanced_accuracy', cv=cv)\n",
        "scores.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeae74ba",
      "metadata": {
        "id": "eeae74ba"
      },
      "outputs": [],
      "source": [
        "modelo = LogisticRegression().fit(X2,y)\n",
        "pd.DataFrame(modelo.coef_,columns=X2.columns).T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "870c73dd",
      "metadata": {
        "id": "870c73dd"
      },
      "source": [
        "<a name=\"roc\"></a>\n",
        "### Curva ROC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df8bdbc2",
      "metadata": {
        "id": "df8bdbc2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "modelo = LogisticRegression()\n",
        "\n",
        "# 1 dividir columnas\n",
        "yColumn = \"label\"\n",
        "XColumns = [c for c in df2.columns if c!=yColumn]\n",
        "X = df[XColumns]\n",
        "y = df[yColumn]\n",
        "\n",
        "# 2 preparar train y test\n",
        "test = 0.4\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= test)\n",
        "\n",
        "y_score = modelo.fit(X_train, y_train).decision_function(X_test)\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "v = np.argmax(tpr - fpr)\n",
        "plt.scatter([fpr[v]],[tpr[v]])\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.01])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Curva ROC, ejemplo autobuses')\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10f910df",
      "metadata": {
        "id": "10f910df"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}