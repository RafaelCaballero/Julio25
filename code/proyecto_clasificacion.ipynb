{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwYUmv5ALv5/TnIAk9tTM2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelCaballero/Julio25/blob/main/code/proyecto_clasificacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introducción a la ciencia de datos con Python\n",
        "Rafael Caballero\n",
        "\n",
        "## Proyecto clasificación\n",
        "\n",
        "Empezamos haciendo la carga y preprocesado, que ya explicamos en detalle en el notebook de regresión"
      ],
      "metadata": {
        "id": "5wK6IMMt91pl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdGZ2PB48wCL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import RepeatedKFold, cross_validate\n",
        "from sklearn.metrics import mean_squared_error, make_scorer\n",
        "from math import sqrt\n",
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import date\n",
        "\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# devuelve los valores Close desde la fecha de inicio hasta hoy\n",
        "# de todos los valoes que se le indican\n",
        "def carga(valores, tickers, start_date='2022-01-01'):\n",
        "  # Fechas de inicio y fin\n",
        "  start_date = '2022-01-01'\n",
        "  hoy = date.today()\n",
        "  end_date = hoy.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "  # Descargar los datos de Yahoo Finance\n",
        "  data = yf.download(tickers, start=start_date, end=end_date, group_by='ticker')\n",
        "\n",
        "  # Crear un DataFrame vacío para almacenar los valores CLOSE\n",
        "  close_data = pd.DataFrame()\n",
        "\n",
        "  # Extraer los valores OPEN de cada ticker y añadirlos al DataFrame\n",
        "  for i,ticker in enumerate(tickers):\n",
        "      nombre = valores[i]\n",
        "      close_data[nombre] = data[ticker]['Close']\n",
        "  return close_data\n",
        "\n",
        "\n",
        "# añade los rendimientos en incremento sobre 100 para cada valor\n",
        "# los rendimientos son columnas nuevas que se añaden al final\n",
        "def ROI(df):\n",
        "  # incremento en porcentaje con respecto al día anterior\n",
        "  roi = df.pct_change()*100\n",
        "  roi.columns = [\"r_\"+c for c in df.columns]\n",
        "  df2 = pd.concat([df,roi],axis=1)\n",
        "  # Establecer el índice como una versión formateada de la fecha\n",
        "  df.index = pd.to_datetime(df.index).strftime('%Y-%m-%d')\n",
        "  return df2.dropna()\n",
        "\n",
        "def dia_semana(df):\n",
        "  # añadimos el día de la semana\n",
        "  df['dia_semana'] = roi.index.to_series().dt.day_name()\n",
        "\n",
        "  # mejor en castellano\n",
        "  days_translation = {\n",
        "      'Monday': 'Lunes',\n",
        "      'Tuesday': 'Martes',\n",
        "      'Wednesday': 'Miércoles',\n",
        "      'Thursday': 'Jueves',\n",
        "      'Friday': 'Viernes',\n",
        "      'Saturday': 'Sábado',\n",
        "      'Sunday': 'Domingo'\n",
        "  }\n",
        "  df['dia_semana'] = df['dia_semana'].map(days_translation)\n",
        "  return pd.get_dummies(df)\n",
        "\n",
        "\n",
        "# sube la columna indicada c la cantidad de pasos indicada para igualarla\n",
        "# con la columna con los datos del día actual\n",
        "def columna_mañana(df,c,dias=1):\n",
        "  df[c+\"_futuro\"] = df[c].shift(-dias)\n",
        "  # al hacerlo han quedado nulos al final, los días de los que no tenemos el fut.\n",
        "  df = df.iloc[:-dias]\n",
        "  return df\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de tickers:\n",
        "valores = [\"inditex\",\"iberdrola\", \"santander\", \"BBVA\", \"naturgy\"]\n",
        "tickers = ['ITX.MC', 'IBE.MC',    'SAN.MC', 'BBVA.MC', 'NTGY.MC']\n",
        "df_raw = carga(valores,tickers)\n",
        "\n",
        "df_roi = ROI(df_raw)\n",
        "df_regresion = columna_mañana(df_roi,\"r_BBVA\")\n",
        "\n",
        "df_regresion"
      ],
      "metadata": {
        "id": "_3mc3bYp_Hfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aun queda un último paso, convertir el problema de regresión en uno de clasificación"
      ],
      "metadata": {
        "id": "T1H-tzPAIqM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_regresion[\"r_BBVA_futuro\"].hist()"
      ],
      "metadata": {
        "id": "lNVFMGLiIyMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtro = df_regresion[\"r_BBVA_futuro\"] > 1 # subidas mayores\n",
        "filtro.mean()"
      ],
      "metadata": {
        "id": "DaGxvJMQIaV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_regresion.copy()\n",
        "df = df.drop(columns=[\"r_BBVA_futuro\"])\n",
        "df[\"label\"] = 0  # se empieza con un valor común, luego se adapta\n",
        "df.loc[filtro,\"label\"] = 1"
      ],
      "metadata": {
        "id": "9u5ewc8mJJ-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "4xslG1_kPxZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clasificación\n",
        "\n",
        "Ahora empieza la clasificación en sí\n",
        "\n",
        "Para ello vamos a definir primero la X y la Y"
      ],
      "metadata": {
        "id": "1BWF8mHAKxJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yColumn = \"label\"\n",
        "XColumns = [c for c in df.columns if c!=\"label\" and c.startswith(\"r_\")]\n",
        "#XColumns = [ 'r_iberdrola',  'r_BBVA', 'r_naturgy']\n",
        "y = df[yColumn]\n",
        "X = df[XColumns]"
      ],
      "metadata": {
        "id": "NUrpgTh8Nqgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#\n",
        "steps = [\n",
        "    ('scale', StandardScaler(with_mean=False)),\n",
        "    ('over', RandomOverSampler()), # para equilibrar, hay que probar otras posibilidades\n",
        "    ('logistic', LogisticRegression(max_iter=10000))\n",
        "]\n",
        "pipeline = Pipeline(steps)\n",
        "\n",
        "# aquí la val. cruzada\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=20)\n",
        "\n",
        "kappa = make_scorer(cohen_kappa_score)\n",
        "\n",
        "scores = cross_val_score(pipeline, X, y, scoring=kappa, cv=cv)\n",
        "\n",
        "print(f\"Cohen’s κ (media ± desv): {scores.mean():.3f} ± {scores.std():.3f}\")"
      ],
      "metadata": {
        "id": "BbsLVemOMnzn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}